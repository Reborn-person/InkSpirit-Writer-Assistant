export async function generateAIContent(
  apiKey: string, 
  systemPrompt: string, 
  userPrompt: string, 
  baseUrl: string = 'https://api.openai.com/v1',
  model: string = 'gpt-4o'
) {
  // ç§»é™¤ baseUrl æœ«å°¾çš„æ–œæ ï¼Œé˜²æ­¢æ‹¼æ¥å‡ºåŒæ–œæ 
  const cleanBaseUrl = baseUrl.replace(/\/$/, '');
  const requestUrl = `${cleanBaseUrl}/chat/completions`;
  
  console.log(`[AI] Requesting completion from: ${requestUrl} (Model: ${model})`);

  try {
    if (!apiKey) {
      throw new Error('API Key is missing. Please set it in Settings.');
    }
  
    if (!baseUrl) {
      throw new Error('Base URL is missing. Please check your API configuration.');
    }
  
    if (!model) {
      throw new Error('Model is missing. Please check your API configuration.');
    }

    const response = await fetch(requestUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.7,
        stream: false
      })
    });

    if (!response.ok) {
      const text = await response.text();
      let errorData: any = {};
      try {
        errorData = JSON.parse(text);
      } catch {
        // å¿½ç•¥è§£æé”™è¯¯ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬ä½œä¸ºé”™è¯¯ä¿¡æ¯
      }
      
      const errorMessage = errorData.error?.message || text.slice(0, 200) || `API request failed with status ${response.status}`;
      
      // æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
      if (response.status === 401) {
        throw new Error(`API è®¤è¯å¤±è´¥ (401): è¯·æ£€æŸ¥æ‚¨çš„ API å¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚${errorMessage}`);
      } else if (response.status === 403) {
        throw new Error(`API æƒé™é”™è¯¯ (403): æ‚¨çš„ API å¯†é’¥å¯èƒ½æ²¡æœ‰è®¿é—®è¯¥æ¨¡å‹æˆ–æœåŠ¡çš„æƒé™ã€‚${errorMessage}`);
      } else if (response.status === 429) {
        throw new Error(`API è¯·æ±‚é¢‘ç‡é™åˆ¶ (429): è¯·ç¨åå†è¯•ã€‚${errorMessage}`);
      } else if (response.status === 500) {
        throw new Error(`API æœåŠ¡å™¨é”™è¯¯ (500): æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚${errorMessage}`);
      } else {
        throw new Error(`API é”™è¯¯ (${response.status}): ${errorMessage}`);
      }
    }

    const text = await response.text();
    let data;
    try {
      data = JSON.parse(text);
    } catch (e) {
      console.error('JSON Parse Error:', e);
      console.error('Response Text:', text.slice(0, 200));
      
      // å°è¯•æå– HTML title ä½œä¸ºæ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
      const titleMatch = text.match(/<title>(.*?)<\/title>/i);
      const pageTitle = titleMatch ? titleMatch[1] : 'Unknown HTML Page';
      
      console.error('--- API Error Debug Info ---');
      console.error('Request URL:', requestUrl);
      console.error('Response Status:', response.status);
      console.error('Response Preview:', text.slice(0, 500));
      console.error('----------------------------');

      let errorMsg = `API è¯·æ±‚è¿”å›äº†ç½‘é¡µè€Œéæ•°æ® (Title: ${pageTitle})ã€‚\n\nè¿”å›å†…å®¹é¢„è§ˆ:\n${text.slice(0, 150)}...`;
      
      // æ™ºèƒ½å»ºè®®ï¼šæ£€æŸ¥æ˜¯å¦ç¼ºå°‘ /v1
      if (!cleanBaseUrl.endsWith('/v1')) {
        errorMsg += `\n\nğŸ’¡ å»ºè®®ï¼šæ‚¨çš„ Base URL (${cleanBaseUrl}) å¯èƒ½ç¼ºå°‘äº† "/v1" åç¼€ã€‚\nè¯·å°è¯•ä¿®æ”¹ä¸º: ${cleanBaseUrl}/v1`;
      } else {
        errorMsg += `\n\nè¯·æ£€æŸ¥ Base URL é…ç½®æ˜¯å¦æ­£ç¡® (å½“å‰: ${cleanBaseUrl})ã€‚`;
      }

      throw new Error(errorMsg);
    }
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      console.error('Invalid API Response Structure:', data);
      throw new Error('API å“åº”æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ: ç¼ºå°‘ choices[0].message å­—æ®µ');
    }
    
    return data.choices[0].message.content;
  } catch (error) {
    console.error('AI Generation Error:', error);
    
    // ç½‘ç»œé”™è¯¯å¤„ç†
    if (error instanceof TypeError && error.message.includes('fetch')) {
      throw new Error('ç½‘ç»œè¿æ¥å¤±è´¥: è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥æˆ– API æœåŠ¡åœ°å€ã€‚');
    }
    
    throw error;
  }
}

export async function generateAIContentStream(
  apiKey: string, 
  systemPrompt: string, 
  userPrompt: string, 
  baseUrl: string = 'https://api.openai.com/v1',
  model: string = 'gpt-4o',
  onUpdate: (content: string) => void
): Promise<string> {
  const cleanBaseUrl = baseUrl.replace(/\/$/, '');
  const requestUrl = `${cleanBaseUrl}/chat/completions`;
  
  console.log(`[AI Stream] Requesting completion from: ${requestUrl} (Model: ${model})`);

  try {
    const response = await fetch(requestUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.7,
        stream: true
      })
    });

    if (!response.ok) {
        // Handle error similarly to non-stream version
        const text = await response.text();
        throw new Error(`API Request Failed: ${response.status} - ${text}`);
    }

    if (!response.body) throw new Error('Response body is null');

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let fullContent = '';
    let buffer = '';

    while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value, { stream: true });
        buffer += chunk;
        const lines = buffer.split('\n');
        buffer = lines.pop() || ''; // Keep the last partial line

        for (const line of lines) {
            const trimmedLine = line.trim();
            if (!trimmedLine || trimmedLine === 'data: [DONE]') continue;
            
            if (trimmedLine.startsWith('data: ')) {
                try {
                    const jsonStr = trimmedLine.slice(6);
                    const data = JSON.parse(jsonStr);
                    const content = data.choices?.[0]?.delta?.content || '';
                    // Also capture reasoning_content if available (for DeepSeek R1)
                    // const reasoning = data.choices?.[0]?.delta?.reasoning_content || ''; 
                    // Note: merging reasoning + content might be confusing without UI support, sticking to content for now.
                    
                    if (content) {
                        fullContent += content;
                        onUpdate(fullContent);
                    }
                } catch (e) {
                    console.warn('Error parsing stream chunk:', e);
                }
            }
        }
    }
    
    return fullContent;

  } catch (error) {
    console.error('AI Stream Generation Error:', error);
    throw error;
  }
}
